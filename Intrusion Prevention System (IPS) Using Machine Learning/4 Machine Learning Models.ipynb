{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2938e86d-8905-460c-a8e9-0c5b6706a916",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7dda1-154a-48d5-8108-4c850fa36005",
   "metadata": {},
   "source": [
    "- **Modelos ML:** Vale a pena mencionar o facto de o seguinte conjunto de dados ser altamente desequilibrado. Por isso, criámos um conjunto de dados equilibrado a partir do nosso conhecimento do domínio para treinar vários modelos ML. Uma vez que o nosso conjunto de dados é bastante grande e tem uma quantidade razoável de amostras para treinar e testar diferentes modelos de ML utilizando vários algoritmos de classificação (Regressão logística, Máquina de vectores de apoio para classificação binária e Classificador de floresta aleatória, Árvore de decisão, K vizinhos mais próximos para classificação multi-classe).\n",
    "\n",
    "  Para classificações binárias, treinámos os modelos para distinguir entre tráfego normal e tráfego anómalo. Isto significa que apenas prevê se está a ocorrer uma intrusão ou não. Em alternativa, utilizando os algoritmos de classificação multi-classe, alargámos ainda mais as nossas capacidades de previsão para identificar o tipo de ataque ou intrusão que está a ocorrer. Experimentámos classificações binárias e classificações multi-classe para ver como os dados se comportam. Posteriormente, efectuámos uma validação cruzada, avaliámos e comparámos esses modelos para ver qual deles funciona melhor ou pior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26a3a68-c412-432b-867a-325f1b6b9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas principais\n",
    "import pandas as pd  # Biblioteca principal para manipulação de dados\n",
    "import numpy as np  # Biblioteca para manipulação numérica, como arrays e operações com matrizes\n",
    "\n",
    "# Importando ferramentas para visualizações\n",
    "import seaborn as sns  # Para visualizações de dados, como heatmaps\n",
    "import matplotlib.pyplot as plt  # Para visualizações, como gráficos\n",
    "from sklearn.decomposition import IncrementalPCA  # Para redução de dimensionalidade com PCA incremental\n",
    "from sklearn.preprocessing import StandardScaler  # Para normalizar os dados\n",
    "from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n",
    "from sklearn.ensemble import RandomForestClassifier  # Algoritmo de aprendizado de máquina\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # Métricas de avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b43a9c3-5972-4580-b9eb-3beb8ccbdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('datasets/CICIDS2017/processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495094fb-b573-4908-9d6b-72d06b7a22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "      <th>PC31</th>\n",
       "      <th>PC32</th>\n",
       "      <th>PC33</th>\n",
       "      <th>PC34</th>\n",
       "      <th>PC35</th>\n",
       "      <th>Attack Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.311094</td>\n",
       "      <td>-0.052684</td>\n",
       "      <td>0.515875</td>\n",
       "      <td>0.616537</td>\n",
       "      <td>3.840727</td>\n",
       "      <td>0.395336</td>\n",
       "      <td>-0.017878</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>-0.680438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233945</td>\n",
       "      <td>0.699887</td>\n",
       "      <td>-0.539784</td>\n",
       "      <td>-0.035279</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.151301</td>\n",
       "      <td>0.051935</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.246553</td>\n",
       "      <td>-0.049159</td>\n",
       "      <td>0.467881</td>\n",
       "      <td>0.395550</td>\n",
       "      <td>2.001551</td>\n",
       "      <td>-0.141045</td>\n",
       "      <td>-0.016487</td>\n",
       "      <td>-0.780967</td>\n",
       "      <td>-0.889976</td>\n",
       "      <td>2.660582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012903</td>\n",
       "      <td>0.543839</td>\n",
       "      <td>0.785574</td>\n",
       "      <td>0.212940</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>-0.058324</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.258822</td>\n",
       "      <td>-0.049501</td>\n",
       "      <td>0.473634</td>\n",
       "      <td>0.408672</td>\n",
       "      <td>2.081408</td>\n",
       "      <td>-0.132962</td>\n",
       "      <td>-0.016754</td>\n",
       "      <td>-0.769681</td>\n",
       "      <td>-0.877466</td>\n",
       "      <td>2.634068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020362</td>\n",
       "      <td>0.539934</td>\n",
       "      <td>0.780933</td>\n",
       "      <td>0.203564</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>-0.064384</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.249188</td>\n",
       "      <td>-0.050635</td>\n",
       "      <td>0.467051</td>\n",
       "      <td>0.346824</td>\n",
       "      <td>2.013841</td>\n",
       "      <td>-0.106530</td>\n",
       "      <td>-0.016178</td>\n",
       "      <td>-0.745133</td>\n",
       "      <td>-0.840229</td>\n",
       "      <td>2.506786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>0.175826</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.047573</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>-0.033301</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.311090</td>\n",
       "      <td>-0.052685</td>\n",
       "      <td>0.515877</td>\n",
       "      <td>0.616515</td>\n",
       "      <td>3.840698</td>\n",
       "      <td>0.395327</td>\n",
       "      <td>-0.017879</td>\n",
       "      <td>0.186543</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>-0.680454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233960</td>\n",
       "      <td>0.699809</td>\n",
       "      <td>-0.539762</td>\n",
       "      <td>-0.035319</td>\n",
       "      <td>0.023078</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.151311</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0 -2.311094 -0.052684  0.515875  0.616537  3.840727  0.395336 -0.017878   \n",
       "1 -2.246553 -0.049159  0.467881  0.395550  2.001551 -0.141045 -0.016487   \n",
       "2 -2.258822 -0.049501  0.473634  0.408672  2.081408 -0.132962 -0.016754   \n",
       "3 -2.249188 -0.050635  0.467051  0.346824  2.013841 -0.106530 -0.016178   \n",
       "4 -2.311090 -0.052685  0.515877  0.616515  3.840698  0.395327 -0.017879   \n",
       "\n",
       "        PC8       PC9      PC10  ...      PC27      PC28      PC29      PC30  \\\n",
       "0  0.186557  0.370079 -0.680438  ... -0.233945  0.699887 -0.539784 -0.035279   \n",
       "1 -0.780967 -0.889976  2.660582  ... -0.012903  0.543839  0.785574  0.212940   \n",
       "2 -0.769681 -0.877466  2.634068  ... -0.020362  0.539934  0.780933  0.203564   \n",
       "3 -0.745133 -0.840229  2.506786  ... -0.027380  0.175826  0.802770  0.063856   \n",
       "4  0.186543  0.370100 -0.680454  ... -0.233960  0.699809 -0.539762 -0.035319   \n",
       "\n",
       "       PC31      PC32      PC33      PC34      PC35  Attack Types  \n",
       "0  0.023075  0.001733  0.045647  0.151301  0.051935        BENIGN  \n",
       "1  0.030939  0.001218  0.025860  0.009198 -0.058324        BENIGN  \n",
       "2  0.034717  0.001194  0.025898  0.005914 -0.064384        BENIGN  \n",
       "3  0.047573  0.001131  0.009281  0.018965 -0.033301        BENIGN  \n",
       "4  0.023078  0.001733  0.045645  0.151311  0.051946        BENIGN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24acaa7-87ec-4f84-be16-097cd80871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cross validation\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51973a87-2195-427e-8160-a34fff6f51ea",
   "metadata": {},
   "source": [
    "## 4.1. Criando um conjunto de dados balanceado para classificação binária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fedcc1-ffde-4bc5-a0e5-0f945aec77f9",
   "metadata": {},
   "source": [
    "Sabemos que um conjunto de dados equilibrado é crucial na aprendizagem automática porque garante que cada classe ou categoria de dados é representada de forma igual. Isto significa que o número de observações em cada classe é aproximadamente o mesmo, o que evita que o modelo seja enviesado para a classe maioritária. Um conjunto de dados enviesado pode levar a um fraco desempenho do modelo, uma vez que este pode ter dificuldade em prever as classes minoritárias. Como já sabemos que o seguinte conjunto de dados é altamente desequilibrado, recorremos à ajuda da SMOTE (Synthetic Minority Over-sampling Technique) para aumentar a amostragem das classes minoritárias enquanto criamos um conjunto de dados equilibrado para a classificação multiclasse. Isto ajudou-nos a criar um conjunto de dados globalmente equilibrado para alimentar os modelos de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ce336e-d305-4a2f-a339-e30f57e0a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o tráfego normal (BENIGN) do tráfego de intrusão (outros tipos de ataque)\n",
    "normal_traffic = new_data.loc[new_data['Attack Types'] == 'BENIGN']  # Seleciona todas as linhas onde o ataque é BENIGN (tráfego normal)\n",
    "intrusions = new_data.loc[new_data['Attack Types'] != 'BENIGN']  # Seleciona todas as linhas onde o ataque é diferente de BENIGN (intrusões)\n",
    "\n",
    "# Amostrando o mesmo número de exemplos de tráfego normal para igualar ao número de intrusões\n",
    "normal_traffic = normal_traffic.sample(n=len(intrusions), replace=False)  # Pega uma amostra aleatória do tráfego normal com o mesmo tamanho do tráfego de intrusões\n",
    "\n",
    "# Combinando as amostras de intrusão e tráfego normal em um novo DataFrame balanceado\n",
    "ids_data = pd.concat([intrusions, normal_traffic])  # Concatena as duas amostras para formar um dataset balanceado\n",
    "\n",
    "# Convertendo a coluna 'Attack Type' em uma variável binária:\n",
    "# 0 para tráfego normal (BENIGN) e 1 para intrusão (outros ataques)\n",
    "ids_data['Attack Types'] = np.where((ids_data['Attack Types'] == 'BENIGN'), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea79253-80d5-48de-b203-d645007b7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset balanceado: 851756 registros\n",
      "\n",
      "Distribuição das classes:\n",
      "Attack Types\n",
      "1    425878\n",
      "0    425878\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando o número total de registros no dataset balanceado\n",
    "print(f'Tamanho do dataset balanceado: {ids_data.shape[0]} registros')\n",
    "\n",
    "# Contando a quantidade de registros de cada classe (0 = BENIGN, 1 = Intrusão)\n",
    "print('\\nDistribuição das classes:')\n",
    "print(ids_data['Attack Types'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10f31db-1cbb-42c4-9d94-6f239f6635f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Types\n",
      "0    150084\n",
      "1    149916\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Criando uma amostra final de 15.000 registros para análise ou treinamento\n",
    "bc_data = ids_data.sample(n=300000)  # Reduz o dataset balanceado para 15.000 amostras, escolhendo aleatoriamente\n",
    "\n",
    "# Imprimindo a contagem de classes para verificar o balanceamento final\n",
    "print(bc_data['Attack Types'].value_counts())  # Exibe a quantidade de registros para cada classe (0 ou 1) no dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb63e67-a76c-4687-bdc3-ea9a34e4dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a função train_test_split do módulo sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando os dados em características (X) e a variável alvo (y)\n",
    "X_bc = bc_data.drop('Attack Types', axis=1)  # 'X_bc' contém todas as colunas, exceto 'Attack Type'\n",
    "y_bc = bc_data['Attack Types']  # 'y_bc' contém apenas a coluna 'Attack Type', que é a variável alvo\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(\n",
    "    X_bc,              # Dados de entrada (features)\n",
    "    y_bc,              # Variável alvo (target)\n",
    "    test_size=0.25,    # 25% dos dados serão usados para o conjunto de teste, 75% para treinamento\n",
    "    random_state=0     # Garante que a divisão dos dados seja reproduzível (mesma divisão a cada execução)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7cb180-65f4-400d-bb6e-9d865aa5993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "      <th>PC31</th>\n",
       "      <th>PC32</th>\n",
       "      <th>PC33</th>\n",
       "      <th>PC34</th>\n",
       "      <th>PC35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219977</th>\n",
       "      <td>-1.920537</td>\n",
       "      <td>-0.037763</td>\n",
       "      <td>0.205313</td>\n",
       "      <td>-0.220464</td>\n",
       "      <td>0.573357</td>\n",
       "      <td>0.555330</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>-0.047656</td>\n",
       "      <td>-0.692434</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522395</td>\n",
       "      <td>-0.154476</td>\n",
       "      <td>-0.677817</td>\n",
       "      <td>-0.986973</td>\n",
       "      <td>-0.432997</td>\n",
       "      <td>0.094646</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.023793</td>\n",
       "      <td>0.210730</td>\n",
       "      <td>0.205771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335488</th>\n",
       "      <td>-1.942302</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>-0.118037</td>\n",
       "      <td>-0.210338</td>\n",
       "      <td>-0.442203</td>\n",
       "      <td>0.665356</td>\n",
       "      <td>0.071809</td>\n",
       "      <td>0.314913</td>\n",
       "      <td>-0.930998</td>\n",
       "      <td>-0.241096</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.265018</td>\n",
       "      <td>-0.537686</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.456290</td>\n",
       "      <td>0.296651</td>\n",
       "      <td>-0.245101</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>-0.018109</td>\n",
       "      <td>0.203309</td>\n",
       "      <td>0.329215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363677</th>\n",
       "      <td>-2.247349</td>\n",
       "      <td>-0.021353</td>\n",
       "      <td>0.309430</td>\n",
       "      <td>0.484723</td>\n",
       "      <td>1.904217</td>\n",
       "      <td>0.776808</td>\n",
       "      <td>0.070743</td>\n",
       "      <td>-0.228512</td>\n",
       "      <td>-1.941442</td>\n",
       "      <td>2.540625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929542</td>\n",
       "      <td>0.038544</td>\n",
       "      <td>0.616835</td>\n",
       "      <td>-2.059240</td>\n",
       "      <td>0.051088</td>\n",
       "      <td>0.135748</td>\n",
       "      <td>-0.001106</td>\n",
       "      <td>0.141669</td>\n",
       "      <td>0.038056</td>\n",
       "      <td>0.076470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403863</th>\n",
       "      <td>-1.920943</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>-0.130051</td>\n",
       "      <td>-0.285585</td>\n",
       "      <td>-0.585648</td>\n",
       "      <td>0.683850</td>\n",
       "      <td>0.072563</td>\n",
       "      <td>0.328974</td>\n",
       "      <td>-0.903561</td>\n",
       "      <td>-0.346551</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.317450</td>\n",
       "      <td>-0.537965</td>\n",
       "      <td>0.161667</td>\n",
       "      <td>0.483445</td>\n",
       "      <td>0.164359</td>\n",
       "      <td>-0.235846</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>-0.035035</td>\n",
       "      <td>0.219783</td>\n",
       "      <td>0.366303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135483</th>\n",
       "      <td>16.422763</td>\n",
       "      <td>-0.450907</td>\n",
       "      <td>-2.528852</td>\n",
       "      <td>-2.491848</td>\n",
       "      <td>1.032512</td>\n",
       "      <td>-1.155682</td>\n",
       "      <td>-0.115230</td>\n",
       "      <td>-2.307312</td>\n",
       "      <td>-0.508401</td>\n",
       "      <td>-2.191145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374749</td>\n",
       "      <td>-1.621366</td>\n",
       "      <td>-1.456983</td>\n",
       "      <td>-0.299889</td>\n",
       "      <td>2.158799</td>\n",
       "      <td>-1.621026</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.050519</td>\n",
       "      <td>-0.082597</td>\n",
       "      <td>0.029701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "219977   -1.920537 -0.037763  0.205313 -0.220464  0.573357  0.555330   \n",
       "335488   -1.942302  0.003643 -0.118037 -0.210338 -0.442203  0.665356   \n",
       "1363677  -2.247349 -0.021353  0.309430  0.484723  1.904217  0.776808   \n",
       "403863   -1.920943  0.002792 -0.130051 -0.285585 -0.585648  0.683850   \n",
       "2135483  16.422763 -0.450907 -2.528852 -2.491848  1.032512 -1.155682   \n",
       "\n",
       "              PC7       PC8       PC9      PC10  ...      PC26      PC27  \\\n",
       "219977   0.033784 -0.047656 -0.692434  0.295734  ...  0.522395 -0.154476   \n",
       "335488   0.071809  0.314913 -0.930998 -0.241096  ... -1.265018 -0.537686   \n",
       "1363677  0.070743 -0.228512 -1.941442  2.540625  ... -0.929542  0.038544   \n",
       "403863   0.072563  0.328974 -0.903561 -0.346551  ... -1.317450 -0.537965   \n",
       "2135483 -0.115230 -2.307312 -0.508401 -2.191145  ...  1.374749 -1.621366   \n",
       "\n",
       "             PC28      PC29      PC30      PC31      PC32      PC33      PC34  \\\n",
       "219977  -0.677817 -0.986973 -0.432997  0.094646  0.001562 -0.023793  0.210730   \n",
       "335488   0.525493  0.456290  0.296651 -0.245101  0.001003 -0.018109  0.203309   \n",
       "1363677  0.616835 -2.059240  0.051088  0.135748 -0.001106  0.141669  0.038056   \n",
       "403863   0.161667  0.483445  0.164359 -0.235846  0.000962 -0.035035  0.219783   \n",
       "2135483 -1.456983 -0.299889  2.158799 -1.621026 -0.000169 -0.050519 -0.082597   \n",
       "\n",
       "             PC35  \n",
       "219977   0.205771  \n",
       "335488   0.329215  \n",
       "1363677  0.076470  \n",
       "403863   0.366303  \n",
       "2135483  0.029701  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bc.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cfd706b-cd5e-4dca-940b-8e69b033e4d5",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definindo a entrada\n",
    "input_dim = X_train_bc.shape[1]  # Número de colunas após o pré-processamento\n",
    "num_classes = len(y_train_bc.unique())  # Número de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada26f2-fdb4-4fab-adaf-1962b2fbe240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "3985c72a-6a82-4814-bf3e-96fa8a344b3f",
   "metadata": {},
   "source": [
    "# Construindo o modelo sequencial para classificação binária\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),  # Primeira camada oculta\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')  # Camada de saída para classificação binária\n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # Perda para problemas binários\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9977e0a5-0870-4a7c-9376-e25d524faa2e",
   "metadata": {},
   "source": [
    "# Early stopping para evitar overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_train_bc, y_train_bc,\n",
    "                    epochs=50,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f33e076-cb49-4d9b-a21f-8d7e28dcb9d4",
   "metadata": {},
   "source": [
    "# Avaliando o modelo no conjunto de teste\n",
    "y_pred = model.predict(X_test_bc)\n",
    "y_pred_classes = y_pred.argmax(axis=1) if num_classes > 2 else (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Relatório de classificação\n",
    "print(classification_report(y_test_bc, y_pred_classes))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test_bc, y_pred_classes)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6262184-41fe-4a41-9240-ea58a9b6f36e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supondo que history seja o histórico do modelo\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "\n",
    "plt.title('Curvas de Aprendizado')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "406e94ed-b539-40e7-825d-8d4e46737286",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supondo que y_test_bc seja o vetor de rótulos verdadeiros e model tenha sido treinado\n",
    "y_pred_proba = model.predict(X_test_bc)  # Probabilidade da classe 1\n",
    "\n",
    "# Converter as probabilidades em rótulos binários usando um limiar de 0.5\n",
    "y_pred_bc = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "cm = confusion_matrix(y_test_bc, y_pred_bc)\n",
    "\n",
    "# Obter os valores de FP e TN da matriz de confusão\n",
    "FP = cm[0, 1]\n",
    "TN = cm[0, 0]\n",
    "\n",
    "# Calcular o False Alarm Rate (FAR)\n",
    "FAR = FP / (FP + TN)\n",
    "print(f\"False Alarm Rate (FAR): {FAR:.4f}\")\n",
    "\n",
    "# Calcular o AUC (Área sob a Curva ROC)\n",
    "auc = roc_auc_score(y_test_bc, y_pred_proba)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Gerar a curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_bc, y_pred_proba)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='b', label=f'ROC Curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.title('Curva ROC')\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed953a6-491c-4bd3-a65c-47b354fec2c5",
   "metadata": {},
   "source": [
    "### 4.2 Testando diferentes Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc461014-c6d6-4a44-8948-581efa260d02",
   "metadata": {},
   "source": [
    "#### 4.2.1 Regressão logística (classificação binária)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a9d89-6850-4e4d-b623-4c7f35bb5ffe",
   "metadata": {},
   "source": [
    "A regressão logística é um tipo de modelo estatístico utilizado para prever a probabilidade de um resultado binário com base numa ou mais variáveis independentes. Modela a relação entre a variável independente e a variável dependente utilizando uma função sigmoide para produzir uma pontuação de probabilidade entre 0 e 1. É frequentemente utilizada em tarefas de classificação em que o objetivo é determinar a qual das duas classes pertence uma observação, como, por exemplo, se um e-mail é spam ou não.\n",
    "\n",
    "Parâmetros:\n",
    "max_iter: este parâmetro define o número máximo de iterações para o solucionador convergir. O valor por defeito é definido como 100. No entanto, o nosso modelo não conseguiu convergir com apenas 100 iterações, pelo que o aumentámos para o valor desejado.\n",
    "\n",
    "C: Este parâmetro é a força de regularização e controla o compromisso entre ajustar bem os dados de treino e evitar o sobreajuste. Um valor mais pequeno de C especifica uma regularização mais forte. Utilizámos um valor mais baixo para um modelo e um valor mais alto para o outro para ver o desempenho dos modelos em termos de evitar o sobreajuste depois de atribuir uma importância elevada e baixa, respetivamente.\n",
    "\n",
    "solver: Este parâmetro especifica o algoritmo a utilizar no problema de otimização quando se ajusta o modelo de regressão logística. Existem vários algoritmos de resolução diferentes disponíveis, tais como lbfgs, saga, liblinear e alguns outros. Optámos por 'saga' e 'sag' para treinar os nossos modelos.\n",
    "\n",
    "random_state: Isto é para garantir que o resultado é determinístico e pode ser reproduzido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef7f0b9-deee-4c4a-af04-e00244ff42a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model 1\n",
      "\n",
      "Cross-validation scores: 0.9320888888888889, 0.9321333333333334, 0.9324, 0.9339777777777778, 0.9310888888888889\n",
      "\n",
      "Mean cross-validation score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Importando a classe LogisticRegression do módulo sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score  # Para validação cruzada\n",
    "\n",
    "# Criando uma instância do modelo de Regressão Logística com parâmetros específicos\n",
    "lr1 = LogisticRegression(\n",
    "    max_iter=10000,      # Define o número máximo de iterações para a convergência do algoritmo\n",
    "    C=0.1,               # Inverso da força de regularização (menores valores = maior regularização)\n",
    "    random_state=0,      # Garante que os resultados sejam reproduzíveis\n",
    "    solver='saga'        # Algoritmo de otimização 'saga' adequado para grandes datasets e regularização\n",
    ")\n",
    "\n",
    "# Treinando o modelo de Regressão Logística com o conjunto de treinamento\n",
    "lr1.fit(X_train_bc, y_train_bc)\n",
    "\n",
    "# Realizando a validação cruzada (cross-validation) com 5 divisões (folds) no conjunto de treinamento\n",
    "cv_lr1 = cross_val_score(lr1, X_train_bc, y_train_bc, cv=5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Logistic Regression Model 1')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_lr1)))  # Imprime os escores individuais\n",
    "print(f'\\nMean cross-validation score: {cv_lr1.mean():.2f}')       # Imprime a média dos escores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75235124-beb6-4879-8a25-c4d3e3acbac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model 1 coefficients:\n",
      "[ 0.61481106 -0.28782001 -0.73968468 -2.22895372  0.93182368  0.84528959\n",
      "  0.00529187  0.50796788 -0.06020218  0.42085667  0.09252799 -0.08415574\n",
      " -0.06952727  0.53110525  0.72171644  0.10740986 -0.02412979 -0.81313946\n",
      " -0.29807555  0.61103451 -0.43693979 -0.6477885   0.58660052  2.43578232\n",
      " -1.43815042 -1.69212272 -2.41827288 -0.51192494 -0.78447961  2.17524913\n",
      "  0.0392921   0.01312341 -4.37151276 -1.26864002  4.04246499]\n",
      "\n",
      "Logistic Regression Model 1 intercept: -3.453152657918483\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os coeficientes do modelo de Regressão Logística\n",
    "print('Logistic Regression Model 1 coefficients:')\n",
    "print(*lr1.coef_, sep=', ')  # Desempacota os coeficientes para exibir cada um separadamente\n",
    "\n",
    "# Exibindo o intercepto do modelo (termo constante)\n",
    "print('\\nLogistic Regression Model 1 intercept:', *lr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3baf55-adf8-4b2b-ad03-211864873f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model 2\n",
      "\n",
      "Cross-validation scores: 0.934, 0.9336, 0.934, 0.9349777777777778, 0.9327555555555556\n",
      "\n",
      "Mean cross-validation score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Criando uma segunda instância do modelo de Regressão Logística com diferentes parâmetros\n",
    "lr2 = LogisticRegression(\n",
    "    max_iter=15000,      # Aumenta o número máximo de iterações para garantir a convergência\n",
    "    solver='sag',        # Utiliza o solver 'sag', eficiente para grandes conjuntos de dados\n",
    "    C=100,               # Menor regularização (C alto significa menos penalização)\n",
    "    random_state=0       # Garante reprodutibilidade dos resultados\n",
    ")\n",
    "\n",
    "# Treinando o modelo de Regressão Logística com o conjunto de treinamento\n",
    "lr2.fit(X_train_bc, y_train_bc)\n",
    "\n",
    "# Realizando validação cruzada (cross-validation) com 5 divisões no conjunto de treinamento\n",
    "cv_lr2 = cross_val_score(lr2, X_train_bc, y_train_bc, cv=5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Logistic Regression Model 2')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_lr2)))  # Imprime os scores individuais de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_lr2.mean():.2f}')       # Imprime a média dos scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "347a143a-ba78-4afe-96eb-582e58011e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model 2 coefficients:\n",
      "[ 6.67985800e-01 -2.74008973e-01 -8.16972578e-01 -2.36073192e+00\n",
      "  1.05044777e+00  8.84889278e-01  3.27564643e-03  5.80710870e-01\n",
      " -7.77714846e-02  4.93411230e-01  1.31633835e-01 -1.31323516e-01\n",
      " -3.69345898e-02  5.56126558e-01  8.13215697e-01  1.03925814e-01\n",
      " -3.18371241e-02 -8.62290917e-01 -3.74177353e-01  6.46039756e-01\n",
      " -4.77008705e-01 -6.81531246e-01  5.61710459e-01  2.55889912e+00\n",
      " -1.63895472e+00 -1.85884196e+00 -2.69932883e+00 -6.65972245e-01\n",
      " -8.71472732e-01  2.53713361e+00  1.44822654e-01  1.60122661e-02\n",
      " -4.93943328e+00 -2.01156298e+00  4.31450119e+00]\n",
      "\n",
      "Logistic Regression Model 2 intercept: -3.629924077835758\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os coeficientes do Modelo 2 de Regressão Logística\n",
    "print('Logistic Regression Model 2 coefficients:')\n",
    "print(*lr2.coef_, sep=', ')  # Desempacota a lista de coeficientes para exibir de forma clara e separada\n",
    "\n",
    "# Exibindo o intercepto do Modelo 2\n",
    "print('\\nLogistic Regression Model 2 intercept:', *lr2.intercept_)  # Mostra o termo constante do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe60f20-e275-4322-a805-f00a2d667eed",
   "metadata": {},
   "source": [
    "#### 4.2.2 Máquina de Vectores de Suporte (Classificação Binária)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e7b73-fe14-48b1-9d41-fdaf9fb93a6c",
   "metadata": {},
   "source": [
    "A máquina de vectores de suporte (SVM) é um tipo de algoritmo de aprendizagem automática supervisionada utilizado para a análise de classificação e regressão. Funciona encontrando um hiperplano num espaço de elevada dimensão que melhor separa os pontos de dados em diferentes classes.\n",
    "\n",
    "Parâmetros:\n",
    "kernel: O parâmetro kernel especifica o tipo de função kernel a utilizar. Neste caso, utilizámos rbf e poly kernel.\n",
    "\n",
    "C: O parâmetro C controla o compromisso entre a maximização da margem e a minimização do erro de classificação.\n",
    "\n",
    "gamma: O parâmetro gamma é um hiperparâmetro que determina a influência de um único exemplo de treinamento no limite de decisão.\n",
    "\n",
    "random_state: Este parâmetro serve para garantir que o resultado seja determinístico e possa ser reproduzido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a3edf-5993-4ee1-aaf8-c845c394fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o modelo de Support Vector Classification (SVC)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Criando uma instância do modelo SVM com um kernel polinomial\n",
    "svm1 = SVC(\n",
    "    kernel='poly',        # Utiliza um kernel polinomial para transformar os dados em um espaço de maior dimensão\n",
    "    C=1,                  # Parâmetro de regularização: controla o equilíbrio entre acerto e generalização\n",
    "    random_state=0,       # Garante reprodutibilidade dos resultados\n",
    "    probability=True      # Ativa a estimativa de probabilidades (necessário para algumas métricas e análises)\n",
    ")\n",
    "\n",
    "# Treinando o modelo SVM com o conjunto de treinamento\n",
    "svm1.fit(X_train_bc, y_train_bc)\n",
    "\n",
    "# Realizando validação cruzada com 5 divisões (folds)\n",
    "cv_svm1 = cross_val_score(svm1, X_train_bc, y_train_bc, cv=5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Support Vector Machine Model 1')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_svm1)))   # Imprime as pontuações individuais de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_svm1.mean():.2f}')         # Exibe a média das pontuações da validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad77be-da3c-4697-9ac8-9f8c5a3dca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância do modelo SVM com kernel RBF (Radial Basis Function)\n",
    "svm2 = SVC(\n",
    "    kernel='rbf',         # O kernel RBF (Radial Basis Function) é utilizado para capturar relações não lineares entre as classes\n",
    "    C=1,                  # Parâmetro de regularização. Um valor maior de C tenta ajustar o modelo o mais possível aos dados de treino, \n",
    "                         # mas pode resultar em overfitting se for grande demais.\n",
    "    gamma=0.1,            # Parâmetro que controla a forma da função kernel. Um valor pequeno de gamma implica que cada ponto de treino\n",
    "                         # tem uma influência maior no modelo, enquanto um valor grande pode resultar em um modelo muito complexo.\n",
    "    random_state=0,       # Garante a reprodutibilidade do modelo com o mesmo valor de semente aleatória.\n",
    "    probability=True      # Habilita o cálculo de probabilidades de previsão, necessário para algumas métricas como log-loss.\n",
    ")\n",
    "\n",
    "# Treinando o modelo SVM com o conjunto de treino (X_train_bc, y_train_bc)\n",
    "svm2.fit(X_train_bc, y_train_bc)\n",
    "\n",
    "# Realizando a validação cruzada (5-fold CV) para avaliar o desempenho do modelo\n",
    "cv_svm2 = cross_val_score(svm2, X_train_bc, y_train_bc, cv=5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Support Vector Machine Model 2')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_svm2)))   # Exibe as pontuações de cada uma das 5 divisões (folds)\n",
    "print(f'\\nMean cross-validation score: {cv_svm2.mean():.2f}')         # Exibe a média das pontuações de todos os folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b849f7f-0f06-43fd-a1dc-82d02e37cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe o intercepto (viés) do modelo SVM 1\n",
    "print('SVM Model 1 intercept:', *svm1.intercept_)\n",
    "\n",
    "# Exibe o intercepto (viés) do modelo SVM 2\n",
    "print('SVM Model 2 intercept:', *svm2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3f16a-81bb-47a1-bd9a-982c45a372d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2. Criação de um conjunto de dados equilibrado para classificação multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd35fa-0b4f-4136-8779-992fb8779cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Attack Types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a707d-1c62-4755-a2eb-564bc08b249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta o número de ocorrências de cada classe (valor único na coluna 'Attack Type')\n",
    "class_counts = new_data['Attack Types'].value_counts()\n",
    "\n",
    "# Seleciona as classes que têm mais do que 1950 registros\n",
    "selected_classes = class_counts[class_counts > 1950]\n",
    "\n",
    "# Extrai os nomes das classes selecionadas\n",
    "class_names = selected_classes.index\n",
    "\n",
    "# Cria um novo DataFrame contendo apenas as classes selecionadas\n",
    "selected = new_data[new_data['Attack Types'].isin(class_names)]\n",
    "\n",
    "# Cria uma lista para armazenar os DataFrames de cada classe selecionada\n",
    "dfs = []\n",
    "\n",
    "# Para cada classe selecionada\n",
    "for name in class_names:\n",
    "  # Filtra o DataFrame para a classe atual\n",
    "  df = selected[selected['Attack Types'] == name]\n",
    "  \n",
    "  # Se o número de registros para essa classe for maior do que 2500, seleciona aleatoriamente 5000 registros\n",
    "  if len(df) > 2500:\n",
    "    df = df.sample(n = 5000, random_state = 0)\n",
    "\n",
    "  # Adiciona o DataFrame da classe à lista\n",
    "  dfs.append(df)\n",
    "\n",
    "# Concatena todos os DataFrames da lista em um único DataFrame, ignorando os índices\n",
    "df = pd.concat(dfs, ignore_index = True)\n",
    "\n",
    "# Exibe a contagem de registros de cada classe no DataFrame resultante\n",
    "df['Attack Types'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f280ad-34ea-41e0-8d38-e2306824335b",
   "metadata": {},
   "source": [
    "método SMOTE (Synthetic Minority Over-sampling Technique) para balancear o dataset, criando novas amostras sintéticas das classes minoritárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2c835-bd93-43eb-8648-59d96bbed8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# X contém as features (características), e y contém os rótulos (Target 'Attack Type')\n",
    "X = df.drop('Attack Types', axis=1)  # Remove a coluna 'Attack Type' para ficar com as features\n",
    "y = df['Attack Types']  # A coluna 'Attack Type' é o target (variável dependente)\n",
    "\n",
    "# Inicializando o SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=0)\n",
    "\n",
    "# Realiza o reamostramento usando o SMOTE, gerando amostras sintéticas\n",
    "X_upsampled, y_upsampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Concatena as novas amostras sintéticas de volta em um DataFrame\n",
    "blnc_data = pd.DataFrame(X_upsampled)\n",
    "\n",
    "# Adiciona a coluna 'Attack Type' ao DataFrame das amostras sintéticas\n",
    "blnc_data['Attack Types'] = y_upsampled\n",
    "\n",
    "# Embaralha os dados para garantir que a distribuição das classes esteja misturada\n",
    "blnc_data = blnc_data.sample(frac=1)\n",
    "\n",
    "# Exibe a distribuição das classes no dataset balanceado\n",
    "blnc_data['Attack Types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3203521-c0b4-45b9-9a00-dd046261fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features (variáveis independentes) e labels (variável dependente)\n",
    "features = blnc_data.drop('Attack Types', axis = 1)\n",
    "labels = blnc_data['Attack Types']\n",
    "\n",
    "# Dividindo os dados em treino e teste (75% treino, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Verificando o tamanho dos dados\n",
    "print(f'Tamanho dos dados de treino: {X_train.shape[0]}')\n",
    "print(f'Tamanho dos dados de teste: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02078e63-2efc-4541-8099-cebf7cc6ac05",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b508a6-11f8-4408-a884-3a1ce95fb3ee",
   "metadata": {},
   "source": [
    "A floresta aleatória é um método de aprendizagem de conjunto que combina várias árvores de decisão para melhorar a precisão e o desempenho de generalização do modelo. A ideia básica por trás das florestas aleatórias é ajustar várias árvores de decisão em subconjuntos aleatórios dos dados de treino e calcular a média das suas previsões para reduzir o sobreajuste e melhorar o desempenho da generalização.\n",
    "\n",
    "Parâmetros:\n",
    "n_estimadores: Este parâmetro especifica o número de árvores de decisão a serem ajustadas na floresta aleatória.\n",
    "\n",
    "max_depth: Este parâmetro especifica a profundidade máxima de cada árvore de decisão na floresta aleatória. Uma árvore mais profunda pode capturar interações mais complexas nos dados. No nosso caso, este parâmetro desempenhou um papel importante na obtenção de melhores resultados.\n",
    "\n",
    "max_features: Este parâmetro especifica o número de caraterísticas a considerar ao procurar a melhor divisão em cada árvore. Treinámos o primeiro modelo tendo em conta todas as caraterísticas e, para o segundo, utilizámos apenas 20 caraterísticas.\n",
    "\n",
    "random_state: Como mencionado anteriormente, este parâmetro serve para garantir que o resultado é determinístico e pode ser reproduzido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ce6e0-25fb-4410-8e9c-756b06371e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Criando o modelo de Random Forest com parâmetros específicos\n",
    "rf1 = RandomForestClassifier(n_estimators = 10, max_depth = 6, max_features = None, random_state = 0)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_rf1 = cross_val_score(rf1, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Random Forest Model 1')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_rf1)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_rf1.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6095db-5be6-4fcb-b56d-b2ed5365f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de Random Forest com parâmetros específicos\n",
    "rf2 = RandomForestClassifier(n_estimators = 15, max_depth = 8, max_features = 20, random_state = 0)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_rf2 = cross_val_score(rf2, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Random Forest Model 2')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_rf2)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_rf2.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8da0df-35cc-49f2-875c-9d38909bc867",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d5521-c75f-43c0-831c-d5c65fcd5655",
   "metadata": {},
   "source": [
    "Uma árvore de decisão é um tipo de algoritmo utilizado na aprendizagem automática para tarefas de classificação e regressão. O algoritmo funciona dividindo recursivamente os dados em subconjuntos mais pequenos, com base nos valores das caraterísticas de entrada, até ser cumprido um critério de paragem. No nosso caso, é a profundidade máxima da árvore.\n",
    "\n",
    "Parâmetros:\n",
    "max_depth: Este parâmetro especifica a profundidade máxima da árvore. Uma árvore mais profunda pode capturar interações mais complexas nos dados, mas pode ser computacionalmente dispendiosa. Começámos com uma profundidade pequena e depois aumentámo-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccc3aa-b930-4db8-9daa-a0e4942041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Criando o modelo de Decision Tree com profundidade máxima de 6\n",
    "dt1 = DecisionTreeClassifier(max_depth = 6)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "dt1.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_dt1 = cross_val_score(dt1, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Decision Tree Model 1')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_dt1)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_dt1.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf26ec-594a-481b-918b-665a5851e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de Decision Tree com profundidade máxima de 8\n",
    "dt2 = DecisionTreeClassifier(max_depth = 8)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "dt2.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_dt2 = cross_val_score(dt2, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('Decision Tree Model 2')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_dt2)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_dt2.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2354d65-3de0-4037-bd41-b5e5fd0885c4",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342cdb7d-0499-4b90-b4b4-46d6819a127c",
   "metadata": {},
   "source": [
    "K Nearest Neighbors (KNN) é um algoritmo simples que procura os k pontos de dados mais próximos (vizinhos) no conjunto de treino para o novo ponto de dados de entrada, com base numa métrica de distância, normalmente a distância euclidiana. Em seguida, o algoritmo adopta um voto maioritário para a classificação das etiquetas ou valores-alvo desses k vizinhos para prever a etiqueta ou o valor-alvo do novo ponto de dados.\n",
    "\n",
    "Parâmetros:\n",
    "n_vizinhos: Este é um hiperparâmetro do algoritmo KNN que especifica o número de vizinhos a considerar ao fazer previsões para um novo ponto de dados de entrada. No nosso caso, começámos inicialmente com 16 para fazer previsões. Assim, o modelo considerará os 16 pontos de dados mais próximos (vizinhos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d2e78-2272-4bba-86b7-dabf0a34d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Criando o modelo de K-Nearest Neighbors com 16 vizinhos\n",
    "knn1 = KNeighborsClassifier(n_neighbors = 16)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_knn1 = cross_val_score(knn1, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('K Nearest Neighbors Model 1')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_knn1)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_knn1.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93cdb26-6a4a-49c0-9164-ea5076812023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de K-Nearest Neighbors com 8 vizinhos\n",
    "knn2 = KNeighborsClassifier(n_neighbors = 8)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "knn2.fit(X_train, y_train)\n",
    "\n",
    "# Realizando a validação cruzada com 5 divisões (folds)\n",
    "cv_knn2 = cross_val_score(knn2, X_train, y_train, cv = 5)\n",
    "\n",
    "# Exibindo os resultados da validação cruzada\n",
    "print('K Nearest Neighbors Model 2')\n",
    "print(f'\\nCross-validation scores:', ', '.join(map(str, cv_knn2)))  # Mostra as pontuações de cada fold\n",
    "print(f'\\nMean cross-validation score: {cv_knn2.mean():.2f}')  # Exibe a média das pontuações de validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2948b-b147-4a0d-8c7d-5560d970163a",
   "metadata": {},
   "source": [
    "# 5. Avaliação e discussão do desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5f62e-2b78-426e-8235-dfc2d2b18a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary functions\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, \\\n",
    " roc_auc_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a701df-b694-43fa-ac3a-7a51053db3e5",
   "metadata": {},
   "source": [
    "### Comparação de modelos de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fa15d-8bb4-4cdf-bccb-1be76d74ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr1 = lr1.predict(X_test_bc)\n",
    "y_pred_lr2 = lr2.predict(X_test_bc)\n",
    "\n",
    "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_lr1)\n",
    "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_lr2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
    "axs[0].set_title('Model 1')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
    "axs[1].set_title('Model 2')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7488ac-e023-4d3d-b8f9-c42a49141227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_lr1 = lr1.predict_proba(X_test_bc)[:,1]\n",
    "y_prob_lr2 = lr2.predict_proba(X_test_bc)[:,1]\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_lr1)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_lr2)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "colors = sns.color_palette('Set2', n_colors = 3)\n",
    "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[0].set_xlim([-0.05, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve (Model 1)')\n",
    "axes[0].legend(loc = 'lower right')\n",
    "\n",
    "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[1].set_xlim([-0.05, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve (Model 2)')\n",
    "axes[1].legend(loc = 'lower right')\n",
    "\n",
    "axes[2].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[2].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[2].set_xlim([-0.05, 1.0])\n",
    "axes[2].set_ylim([0.0, 1.05])\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('Model 1 vs Model 2')\n",
    "axes[2].legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08056552-1a14-4ffd-987f-76110c3c96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_lr1)\n",
    "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_lr2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axs[0].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
    "axs[0].set_xlabel('Recall')\n",
    "axs[0].set_ylabel('Precision')\n",
    "axs[0].set_title('Precision-Recall Curve (Model 1)')\n",
    "\n",
    "axs[1].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
    "axs[1].set_xlabel('Recall')\n",
    "axs[1].set_ylabel('Precision')\n",
    "axs[1].set_title('Precision-Recall Curve (Model 2)')\n",
    "\n",
    "axs[2].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
    "axs[2].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
    "axs[2].set_xlabel('Recall')\n",
    "axs[2].set_ylabel('Precision')\n",
    "axs[2].set_title('Model 1 vs Model 2')\n",
    "axs[2].legend(loc = 'lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db75bf3-acbb-4a66-8d46-dbb12d409b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = lr1.classes_\n",
    "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr1, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "sns.heatmap(data1, cmap='Pastel1', annot = True, fmt='.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "axs[0].set_title('Classification Report (Model 1)')\n",
    "axs[1].set_title('Classification Report (Model 2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c6413-ada0-4fc0-bbe3-23da7dc8c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 3)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_lr1, y_test_bc)\n",
    "acc2 = accuracy_score(y_pred_lr2, y_test_bc)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Logistic Regression Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bddb6-bcb2-402d-9cd2-2f91a1b0ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 3)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [cv_lr1.mean(), cv_lr2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Logistic Regression Model Comparison (Cross Validation)')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a243e0-7801-4b53-8134-40c87650186b",
   "metadata": {},
   "source": [
    "### Comparação de modelos de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ca0b1-b5b2-41dd-8547-91328f88977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm1 = svm1.predict(X_test_bc)\n",
    "y_pred_svm2 = svm2.predict(X_test_bc)\n",
    "\n",
    "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_svm1)\n",
    "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_svm2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
    "axs[0].set_title('Model 1')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
    "axs[1].set_title('Model 2')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd975b6-45f6-4246-beb5-9de2990020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_svm1 = svm1.predict_proba(X_test_bc)[:,1]\n",
    "y_prob_svm2 = svm2.predict_proba(X_test_bc)[:,1]\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_svm1)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_svm2)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[0].set_xlim([-0.05, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve (Model 1)')\n",
    "axes[0].legend(loc = 'lower right')\n",
    "\n",
    "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[1].set_xlim([-0.05, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve (Model 2)')\n",
    "axes[1].legend(loc = 'lower right')\n",
    "\n",
    "axes[2].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[2].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[2].set_xlim([-0.05, 1.0])\n",
    "axes[2].set_ylim([0.0, 1.05])\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('Model 1 vs Model 2')\n",
    "axes[2].legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6dad99-a530-455c-9ae1-826bce86bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_svm1)\n",
    "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_svm2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axs[0].plot(recall1, precision1, color = colors[1])\n",
    "axs[0].set_xlabel('Recall')\n",
    "axs[0].set_ylabel('Precision')\n",
    "axs[0].set_title('Precision-Recall Curve (Model 1)')\n",
    "\n",
    "axs[1].plot(recall2, precision2, color = colors[2])\n",
    "axs[1].set_xlabel('Recall')\n",
    "axs[1].set_ylabel('Precision')\n",
    "axs[1].set_title('Precision-Recall Curve (Model 2)')\n",
    "\n",
    "axs[2].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
    "axs[2].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
    "axs[2].set_xlabel('Recall')\n",
    "axs[2].set_ylabel('Precision')\n",
    "axs[2].set_title('Model 1 vs Model 2')\n",
    "axs[2].legend(loc = 'lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1a8a8-abd7-4d5f-ba30-0e2c6e513edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = svm1.classes_\n",
    "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm1, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "axs[0].set_title('Classification Report (Model 1)')\n",
    "axs[1].set_title('Classification Report (Model 2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717677c-41b6-4fe5-a37f-619df90d3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 2)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_svm1, y_test_bc)\n",
    "acc2 = accuracy_score(y_pred_svm2, y_test_bc)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Support Vector Machine Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58908396-2af1-41f3-903e-3ee0b4b68988",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 2)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [cv_svm1.mean(), cv_svm2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Support Vector Machine Model Comparison (Cross Validation)')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e0106-6041-4980-85ec-351bce1422c5",
   "metadata": {},
   "source": [
    "## Comparação dos algoritmos de classificação binária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c5208-bc64-4290-bf41-63dddcc25879",
   "metadata": {},
   "source": [
    "Treinámos dois modelos para cada algoritmo de classificação diferente. Para comparar os diferentes algoritmos, seleccionaremos o modelo com melhor desempenho de cada classe com base na precisão, recuperação, exatidão, etc. do modelo.\n",
    "\n",
    "1. Regressão logística: Modelo 2\n",
    "2. Máquina de vetor de suporte: Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97258e6-4deb-4393-8df6-e40aab559688",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_model1 = confusion_matrix(y_test_bc, y_pred_lr2)\n",
    "conf_matrix_model2 = confusion_matrix(y_test_bc, y_pred_svm2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0])\n",
    "axs[0].set_title('Logistic Regression')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1])\n",
    "axs[1].set_title('Support Vector Machine')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046d9a7-5454-402f-b35d-5cba2c6cd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1, tpr1, _ = roc_curve(y_test_bc, y_prob_lr2)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_test_bc, y_prob_svm2)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axes[0].plot(fpr1, tpr1, label = f'ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[0].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[0].set_xlim([-0.05, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve (Logistic Regression)')\n",
    "axes[0].legend(loc = 'lower right')\n",
    "\n",
    "axes[1].plot(fpr2, tpr2, label = f'ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[1].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[1].set_xlim([-0.05, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve (SVM)')\n",
    "axes[1].legend(loc = 'lower right')\n",
    "\n",
    "axes[2].plot(fpr1, tpr1, label = f'LR ROC curve (area = {roc_auc1:.2%})', color = colors[1])\n",
    "axes[2].plot(fpr2, tpr2, label = f'SVM ROC curve (area = {roc_auc2:.2%})', color = colors[2])\n",
    "axes[2].plot([0, 1], [0, 1], color = colors[0], linestyle = '--')\n",
    "axes[2].set_xlim([-0.05, 1.0])\n",
    "axes[2].set_ylim([0.0, 1.05])\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('LR vs SVM')\n",
    "axes[2].legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d176f34-b66d-4d6b-b976-088d1c40a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision1, recall1, threshold1 = precision_recall_curve(y_test_bc, y_prob_lr2)\n",
    "precision2, recall2, threshold2 = precision_recall_curve(y_test_bc, y_prob_svm2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "axs[0].plot(recall1, precision1, color = colors[1], label = 'Model 1')\n",
    "axs[0].set_xlabel('Recall')\n",
    "axs[0].set_ylabel('Precision')\n",
    "axs[0].set_title('Precision-Recall Curve (LR)')\n",
    "\n",
    "axs[1].plot(recall2, precision2, color = colors[2], label = 'Model 2')\n",
    "axs[1].set_xlabel('Recall')\n",
    "axs[1].set_ylabel('Precision')\n",
    "axs[1].set_title('Precision-Recall Curve (SVM)')\n",
    "\n",
    "axs[2].plot(recall1, precision1, color = colors[1], label = 'Logistic Regression')\n",
    "axs[2].plot(recall2, precision2, color = colors[2], label = 'Support Vector Machine')\n",
    "axs[2].set_xlabel('Recall')\n",
    "axs[2].set_ylabel('Precision')\n",
    "axs[2].set_title('LR vs SVM')\n",
    "axs[2].legend(loc = 'lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90124c21-ea1b-4ef7-bfc4-f8262728fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = svm2.classes_\n",
    "metrics1 = classification_report(y_true = y_test_bc, y_pred = y_pred_lr2, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test_bc, y_pred = y_pred_svm2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax=axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax=axs[1])\n",
    "axs[0].set_title('Classification Report (LR)')\n",
    "axs[1].set_title('Classification Report (SVM)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccd4c1-c20e-44f7-a71b-8a7a7aef742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 2)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_lr2, y_test_bc)\n",
    "acc2 = accuracy_score(y_pred_svm2, y_test_bc)\n",
    "\n",
    "labels = ['Logistic Regression', 'Support Vector Machine']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Binary Classification Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f73cd0-f634-409f-9e7a-56dc3c8325a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 2)\n",
    "\n",
    "labels = ['Logistic Regression', 'Support Vector Machine']\n",
    "scores = [cv_lr2.mean(), cv_svm2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Binary Classification Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb225d-d8db-450f-9f51-9450d1978083",
   "metadata": {},
   "source": [
    "### Random Forest Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4476884-3339-42db-9b47-1bfa1f29f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf1 = rf1.predict(X_test)\n",
    "y_pred_rf2 = rf2.predict(X_test)\n",
    "\n",
    "conf_matrix_model1 = confusion_matrix(y_test, y_pred_rf1)\n",
    "conf_matrix_model2 = confusion_matrix(y_test, y_pred_rf2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = rf1.classes_, yticklabels = rf1.classes_)\n",
    "axs[0].set_title('Model 1')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = rf2.classes_, yticklabels = rf2.classes_)\n",
    "axs[1].set_title('Model 2')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b67d8-509d-47e0-ad1d-d0b2c68f77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = rf1.classes_\n",
    "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_rf1, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_rf2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "axs[0].set_title('Classification Report (Model 1)')\n",
    "axs[1].set_title('Classification Report (Model 2)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751552f-9a23-41ad-9c32-f8ce1117db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 2)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_rf1, y_test)\n",
    "acc2 = accuracy_score(y_pred_rf2, y_test)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Random Forest Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dec6d0-5a22-4449-96b6-c3e1696a379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 2)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [cv_rf1.mean(), cv_rf2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Support Vector Machine Model Comparison (Cross Validation)')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0b953-5747-4b6d-a3af-cbe62e5e366c",
   "metadata": {},
   "source": [
    "### Decision Trees Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1e4632-c188-4248-866d-62158efbd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt1 = dt1.predict(X_test)\n",
    "y_pred_dt2 = dt2.predict(X_test)\n",
    "\n",
    "conf_matrix_model1 = confusion_matrix(y_test, y_pred_dt1)\n",
    "conf_matrix_model2 = confusion_matrix(y_test, y_pred_dt2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
    "axs[0].set_title('Model 1')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = dt2.classes_, yticklabels = dt2.classes_)\n",
    "axs[1].set_title('Model 2')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df9451-128f-4d64-8096-5a01672b82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = dt1.classes_\n",
    "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_dt1, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_dt2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "axs[0].set_title('Classification Report (Model 1)')\n",
    "axs[1].set_title('Classification Report (Model 2)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba04eb0-63f2-4ea0-afaf-6e5e57349ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 2)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_dt1, y_test)\n",
    "acc2 = accuracy_score(y_pred_dt2, y_test)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Decision Trees Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c8669-df63-47bf-ac18-468e96171227",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 2)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [cv_dt1.mean(), cv_dt2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Decision Trees Model Comparison (Cross Validation)')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da72cf-89e1-4fdd-86a7-b9c89b998cc4",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557eafd-f22d-46e4-add3-1420cf729d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn1 = knn1.predict(X_test)\n",
    "y_pred_knn2 = knn2.predict(X_test)\n",
    "\n",
    "conf_matrix_model1 = confusion_matrix(y_test, y_pred_knn1)\n",
    "conf_matrix_model2 = confusion_matrix(y_test, y_pred_knn2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (16, 7))\n",
    "\n",
    "sns.heatmap(conf_matrix_model1, annot = True, cmap = 'Blues', ax = axs[0], xticklabels = knn1.classes_, yticklabels = knn1.classes_)\n",
    "axs[0].set_title('Model 1')\n",
    "\n",
    "sns.heatmap(conf_matrix_model2, annot = True, cmap = 'Blues', ax = axs[1], xticklabels = knn2.classes_, yticklabels = knn2.classes_)\n",
    "axs[1].set_title('Model 2')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b28083-25d3-4cf5-865e-62a031aabae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = knn1.classes_\n",
    "metrics1 = classification_report(y_true = y_test, y_pred = y_pred_knn1, target_names = target_names, output_dict = True)\n",
    "precision1 = [metrics1[target_name]['precision'] for target_name in target_names]\n",
    "recall1 = [metrics1[target_name]['recall'] for target_name in target_names]\n",
    "f1_score1 = [metrics1[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "metrics2 = classification_report(y_true = y_test, y_pred = y_pred_knn2, target_names = target_names, output_dict = True)\n",
    "precision2 = [metrics2[target_name]['precision'] for target_name in target_names]\n",
    "recall2 = [metrics2[target_name]['recall'] for target_name in target_names]\n",
    "f1_score2 = [metrics2[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "data1 = np.array([precision1, recall1, f1_score1])\n",
    "data2 = np.array([precision2, recall2, f1_score2])\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "sns.heatmap(data1, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(data2, cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "axs[0].set_title('Classification Report (Model 1)')\n",
    "axs[1].set_title('Classification Report (Model 2)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b401d87-3d82-4d44-a9b3-f48f1f33ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 2)\n",
    "\n",
    "acc1 = accuracy_score(y_pred_knn1, y_test)\n",
    "acc2 = accuracy_score(y_pred_knn2, y_test)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [acc1, acc2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('K Nearest Neighbour Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d46e8f-a2e5-4348-95b9-0aee78b60f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 2)\n",
    "\n",
    "labels = ['Model 1', 'Model 2']\n",
    "scores = [cv_knn1.mean(), cv_knn2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Decision Trees Model Comparison (Cross Validation)')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 3)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4724d7-8e95-4394-b1ef-cafb7f1a9fde",
   "metadata": {},
   "source": [
    "### Comparação dos algoritmos de classificação multi-classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05c6fc-e7fb-45d5-906d-cf13244b330a",
   "metadata": {},
   "source": [
    "Treinámos dois modelos para cada algoritmo de classificação diferente. Para comparar os diferentes algoritmos, seleccionaremos o modelo com melhor desempenho de cada classe, com base na precisão, recuperação, exatidão, etc. do modelo.\n",
    "\n",
    "Floresta aleatória: Modelo 2\n",
    "Árvores de decisão: Modelo 2\n",
    "KNN: Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a635a7-049e-4653-9cee-edb9a783188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Blues', n_colors = 3)\n",
    "\n",
    "rf_acc = accuracy_score(y_pred_rf2, y_test)\n",
    "dt_acc = accuracy_score(y_pred_dt2, y_test)\n",
    "knn_acc = accuracy_score(y_pred_knn2, y_test)\n",
    "\n",
    "labels = ['Random Forest', 'Decision Trees', 'K Nearest Neighbours']\n",
    "scores = [rf_acc, dt_acc, knn_acc]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Accuracy Score')\n",
    "ax.set_title('Multi-class Classification Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 4)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc75c7e-77ef-4287-b9fa-16a8ec58c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Greens', n_colors = 3)\n",
    "\n",
    "labels = ['Random Forest', 'Decision Trees', 'K Nearest Neighbours']\n",
    "scores = [cv_rf2.mean(), cv_dt2.mean(), cv_knn2.mean()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9, 3))\n",
    "ax.barh(labels, scores, color = palette)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Cross Validation Score')\n",
    "ax.set_title('Multi-class Classification Model Comparison')\n",
    "\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(v + 0.01, i, str(round(v, 4)), ha = 'left', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e1638-5c47-4dda-b2c8-4e7885ee1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = rf2.classes_\n",
    "preds = [y_pred_rf2, y_pred_dt2, y_pred_knn2]\n",
    "\n",
    "datas = []\n",
    "for pred in preds:\n",
    "    metrics = classification_report(y_true = y_test, y_pred = pred, target_names = target_names, output_dict = True)\n",
    "    precision = [metrics[target_name]['precision'] for target_name in target_names]\n",
    "    recall = [metrics[target_name]['recall'] for target_name in target_names]\n",
    "    f1_score = [metrics[target_name]['f1-score'] for target_name in target_names]\n",
    "\n",
    "    datas.append(np.array([precision, recall, f1_score]))\n",
    "\n",
    "rows = ['Precision', 'Recall', 'F1-score']\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (19, 6))\n",
    "sns.heatmap(datas[0], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[0])\n",
    "sns.heatmap(datas[1], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[1])\n",
    "sns.heatmap(datas[2], cmap = 'Pastel1', annot = True, fmt = '.2f', xticklabels = target_names, yticklabels = rows, ax = axs[2])\n",
    "\n",
    "axs[0].set_title('Classification Report (Random Forest)')\n",
    "axs[1].set_title('Classification Report (Decision Trees)')\n",
    "axs[2].set_title('Classification Report (K Nearest Neighbours)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f8dfa-727e-43b2-ba37-0434395afbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [y_pred_rf2, y_pred_dt2, y_pred_knn2]\n",
    "\n",
    "conf_matrix = [confusion_matrix(y_test, y_pred) for y_pred in preds]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (22, 8))\n",
    "\n",
    "sns.heatmap(conf_matrix[0], annot = True, cmap = 'Blues', ax = axs[0], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
    "sns.heatmap(conf_matrix[1], annot = True, cmap = 'Blues', ax = axs[1], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
    "sns.heatmap(conf_matrix[2], annot = True, cmap = 'Blues', ax = axs[2], xticklabels = dt1.classes_, yticklabels = dt1.classes_)\n",
    "\n",
    "axs[0].set_title('Confusion Matrix (Random Forest)')\n",
    "axs[1].set_title('Confusion Matrix (Decision Trees)')\n",
    "axs[2].set_title('Confusion Matrix (K Nearest Neighbours)')\n",
    "\n",
    "axs[0].set_xlabel('Predicted label')\n",
    "axs[1].set_xlabel('Predicted label')\n",
    "axs[2].set_xlabel('Predicted label')\n",
    "axs[0].set_ylabel('True label')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68a100-b0ed-4b52-b59f-beced1ad68e5",
   "metadata": {},
   "source": [
    "Durante a fase de treino de vários algoritmos de classificação, treinámos dois modelos para cada um dos algoritmos utilizando parâmetros diferentes.\n",
    "\n",
    "***Algoritmos de classificação binária: ***\n",
    "1. Regressão logística\n",
    "2. Máquina de vectores de apoio\n",
    "\n",
    "Para comparar os diferentes algoritmos de classificação, utilizámos os modelos com melhor desempenho de cada algoritmo.\n",
    "\n",
    "Com base nos nossos vários testes, descobrimos que a regressão logística pode lidar com dados de grande dimensão e pode ser treinada num período de tempo muito curto. No entanto, a desvantagem são os modelos menos exactos. Por outro lado, o SVM é bastante dispendioso do ponto de vista computacional e demora muito tempo a ser treinado, mas o aspeto positivo é que a pontuação de precisão é muito superior à dos modelos de regressão logística. Ajustámos alguns parâmetros aqui e ali para melhorar a precisão dos modelos. Também fizemos uma validação cruzada para garantir que o nosso modelo não estava sobreajustado e que tinha sido treinado corretamente.\n",
    "\n",
    "Um outro aspeto a mencionar é que a precisão dos modelos depende da normalização do conjunto de dados. Treinámos o nosso modelo com e sem a utilização de um scaler padrão. Durante o teste de diferentes modelos, descobrimos que a precisão e outras pontuações de medidas de desempenho aumentaram significativamente após a normalização do conjunto de dados. Por isso, optámos por normalizar os dados antes de aplicar o PCA.\n",
    "\n",
    "***Algoritmos de classificação multi-classe: ***\n",
    "1. Floresta aleatória\n",
    "2. Árvores de decisão\n",
    "3. K Vizinhos mais próximos\n",
    "\n",
    "Mais uma vez, para comparar os diferentes algoritmos de classificação, utilizámos os modelos com melhor desempenho de cada um dos 3 algoritmos.\n",
    "\n",
    "O tempo necessário para treinar os modelos de classificação multi-classe é relativamente inferior ao dos modelos de classificação binária. Isto pode dever-se ao facto de a dimensão dos dados de treino ser inferior à dos dados de treino da classificação binária.\n",
    "\n",
    "Tal como indicado na secção de análise, o conjunto de dados é altamente desequilibrado. A fim de manter os dados equilibrados em todas as classes, começámos por recolher o maior número de amostras das classes minoritárias e um número suficiente de amostras das classes maioritárias. Mais tarde, utilizámos a técnica SMOTE (Synthetic Minority Over-sampling Technique) para criar um conjunto de dados globalmente equilibrado para treinar os modelos de classificação multiclasse.\n",
    "\n",
    "Ao comparar as métricas de desempenho dos modelos, verificamos que a Floresta Aleatória é o modelo com melhor desempenho, seguido do KNN e da Árvore de Decisão. A partir da matriz de confusão e do relatório de classificação, é evidente o domínio da Floresta Aleatória em termos de precisão, recuperação e pontuação f1. A razão pela qual a Árvore de Decisão fica para trás é o facto de nem sempre ser suficientemente expressiva para captar relações complexas entre as caraterísticas de entrada e a variável-alvo. A árvore de decisão pode ter dificuldades com problemas em que a variável-alvo depende de uma combinação de caraterísticas de entrada em vez de apenas uma ou duas caraterísticas. O KNN e o Random Forest podem lidar com relações mais complexas entre as caraterísticas de entrada e a variável-alvo, utilizando modelos mais flexíveis. Além disso, utilizámos relativamente menos parâmetros para ajustar os modelos de árvore de decisão. Tal como os algoritmos de classificação binária, também efectuámos uma validação cruzada dos modelos de classificação multi-classe para garantir que não estavam demasiado ajustados.\n",
    "\n",
    "**Trabalho futuro:** Tendo isto em mente, temos de escolher o nosso modelo em conformidade se quisermos ficar com um só. No entanto, neste caso, também podemos combinar os classificadores KNN e Random Forest utilizando um método de conjunto. Isto pode melhorar a precisão do nosso sistema de deteção de intrusões, aproveitando os pontos fortes de ambos os modelos e reduzindo o risco de sobreajuste. O método de conjunto permitiria que os modelos trabalhassem em conjunto para produzir uma previsão mais robusta, que poderia ser mais eficaz na identificação de diferentes tipos de ataque à rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9e99a-0272-4de2-9efd-36adced90ea1",
   "metadata": {},
   "source": [
    "# 6. Salvar o Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dead7-e33f-4e76-8248-8a6b2ddc003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # Biblioteca para salvar modelos\n",
    "import os\n",
    "\n",
    "# nn_model = Rede Neural treinada\n",
    "# svm_model = SVM treinado\n",
    "\n",
    "# Diretório onde os modelos serão salvos\n",
    "output_dir = \"modelos_salvos\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Salvando o modelo da Rede Neural\n",
    "#joblib.dump(model, os.path.join(output_dir, 'neural_network_model.pkl'))\n",
    "\n",
    "# Salvando o modelo SVM (Máquina de Vetores de Suporte)\n",
    "joblib.dump(svm2, os.path.join(output_dir, 'svm_model_impl.pkl'))\n",
    "\n",
    "print(\"Modelos salvos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRproj",
   "language": "python",
   "name": "srproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
